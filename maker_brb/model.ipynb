{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit ('maker-brb-cDHtcBba-py3.7': venv)",
   "metadata": {
    "interpreter": {
     "hash": "e4aaffc62994aec7e91b56940e0c741daf2e57033edf4147497eb1c58fd49bd3"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "y = torch.tensor(0.6, requires_grad=True)\n",
    "pow = torch.pow(y,x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(0.3600, grad_fn=<PowBackward1>)\n"
     ]
    }
   ],
   "source": [
    "print(pow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pow_tensor = pow.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([0.3600], grad_fn=<UnsqueezeBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "pow_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pow.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(-0.1839)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(1.2000)"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "y.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([0.4000])"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "y = torch.tensor([0.4])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(0.0016, grad_fn=<MseLossBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "loss = loss_func(pow_tensor, y)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam([x,y],lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\tloss:tensor(0.0016, grad_fn=<MseLossBackward>)\tpow: tensor(0.3600, grad_fn=<PowBackward1>)\n1\tloss:tensor(0.0007, grad_fn=<MseLossBackward>)\tpow: tensor(0.3739, grad_fn=<PowBackward1>)\n2\tloss:tensor(0.0002, grad_fn=<MseLossBackward>)\tpow: tensor(0.3877, grad_fn=<PowBackward1>)\n3\tloss:tensor(1.4670e-07, grad_fn=<MseLossBackward>)\tpow: tensor(0.4004, grad_fn=<PowBackward1>)\n4\tloss:tensor(0.0001, grad_fn=<MseLossBackward>)\tpow: tensor(0.4109, grad_fn=<PowBackward1>)\n5\tloss:tensor(0.0003, grad_fn=<MseLossBackward>)\tpow: tensor(0.4178, grad_fn=<PowBackward1>)\n6\tloss:tensor(0.0004, grad_fn=<MseLossBackward>)\tpow: tensor(0.4207, grad_fn=<PowBackward1>)\n7\tloss:tensor(0.0004, grad_fn=<MseLossBackward>)\tpow: tensor(0.4203, grad_fn=<PowBackward1>)\n8\tloss:tensor(0.0003, grad_fn=<MseLossBackward>)\tpow: tensor(0.4174, grad_fn=<PowBackward1>)\n9\tloss:tensor(0.0002, grad_fn=<MseLossBackward>)\tpow: tensor(0.4130, grad_fn=<PowBackward1>)\n10\tloss:tensor(5.8963e-05, grad_fn=<MseLossBackward>)\tpow: tensor(0.4077, grad_fn=<PowBackward1>)\n11\tloss:tensor(4.5169e-06, grad_fn=<MseLossBackward>)\tpow: tensor(0.4021, grad_fn=<PowBackward1>)\n12\tloss:tensor(9.4304e-06, grad_fn=<MseLossBackward>)\tpow: tensor(0.3969, grad_fn=<PowBackward1>)\n13\tloss:tensor(5.4744e-05, grad_fn=<MseLossBackward>)\tpow: tensor(0.3926, grad_fn=<PowBackward1>)\n14\tloss:tensor(0.0001, grad_fn=<MseLossBackward>)\tpow: tensor(0.3895, grad_fn=<PowBackward1>)\n15\tloss:tensor(0.0001, grad_fn=<MseLossBackward>)\tpow: tensor(0.3879, grad_fn=<PowBackward1>)\n16\tloss:tensor(0.0002, grad_fn=<MseLossBackward>)\tpow: tensor(0.3877, grad_fn=<PowBackward1>)\n17\tloss:tensor(0.0001, grad_fn=<MseLossBackward>)\tpow: tensor(0.3887, grad_fn=<PowBackward1>)\n18\tloss:tensor(8.3349e-05, grad_fn=<MseLossBackward>)\tpow: tensor(0.3909, grad_fn=<PowBackward1>)\n19\tloss:tensor(3.9255e-05, grad_fn=<MseLossBackward>)\tpow: tensor(0.3937, grad_fn=<PowBackward1>)\n20\tloss:tensor(9.0540e-06, grad_fn=<MseLossBackward>)\tpow: tensor(0.3970, grad_fn=<PowBackward1>)\n21\tloss:tensor(7.8196e-08, grad_fn=<MseLossBackward>)\tpow: tensor(0.4003, grad_fn=<PowBackward1>)\n22\tloss:tensor(1.0571e-05, grad_fn=<MseLossBackward>)\tpow: tensor(0.4033, grad_fn=<PowBackward1>)\n23\tloss:tensor(3.1404e-05, grad_fn=<MseLossBackward>)\tpow: tensor(0.4056, grad_fn=<PowBackward1>)\n24\tloss:tensor(5.0700e-05, grad_fn=<MseLossBackward>)\tpow: tensor(0.4071, grad_fn=<PowBackward1>)\n25\tloss:tensor(5.9250e-05, grad_fn=<MseLossBackward>)\tpow: tensor(0.4077, grad_fn=<PowBackward1>)\n26\tloss:tensor(5.4040e-05, grad_fn=<MseLossBackward>)\tpow: tensor(0.4074, grad_fn=<PowBackward1>)\n27\tloss:tensor(3.8482e-05, grad_fn=<MseLossBackward>)\tpow: tensor(0.4062, grad_fn=<PowBackward1>)\n28\tloss:tensor(1.9844e-05, grad_fn=<MseLossBackward>)\tpow: tensor(0.4045, grad_fn=<PowBackward1>)\n29\tloss:tensor(5.5466e-06, grad_fn=<MseLossBackward>)\tpow: tensor(0.4024, grad_fn=<PowBackward1>)\n30\tloss:tensor(3.0333e-08, grad_fn=<MseLossBackward>)\tpow: tensor(0.4002, grad_fn=<PowBackward1>)\n31\tloss:tensor(3.3465e-06, grad_fn=<MseLossBackward>)\tpow: tensor(0.3982, grad_fn=<PowBackward1>)\n32\tloss:tensor(1.1802e-05, grad_fn=<MseLossBackward>)\tpow: tensor(0.3966, grad_fn=<PowBackward1>)\n33\tloss:tensor(2.0131e-05, grad_fn=<MseLossBackward>)\tpow: tensor(0.3955, grad_fn=<PowBackward1>)\n34\tloss:tensor(2.4053e-05, grad_fn=<MseLossBackward>)\tpow: tensor(0.3951, grad_fn=<PowBackward1>)\n35\tloss:tensor(2.2007e-05, grad_fn=<MseLossBackward>)\tpow: tensor(0.3953, grad_fn=<PowBackward1>)\n36\tloss:tensor(1.5400e-05, grad_fn=<MseLossBackward>)\tpow: tensor(0.3961, grad_fn=<PowBackward1>)\n37\tloss:tensor(7.5171e-06, grad_fn=<MseLossBackward>)\tpow: tensor(0.3973, grad_fn=<PowBackward1>)\n38\tloss:tensor(1.7460e-06, grad_fn=<MseLossBackward>)\tpow: tensor(0.3987, grad_fn=<PowBackward1>)\n39\tloss:tensor(1.9846e-08, grad_fn=<MseLossBackward>)\tpow: tensor(0.4001, grad_fn=<PowBackward1>)\n40\tloss:tensor(2.1180e-06, grad_fn=<MseLossBackward>)\tpow: tensor(0.4015, grad_fn=<PowBackward1>)\n41\tloss:tensor(6.0651e-06, grad_fn=<MseLossBackward>)\tpow: tensor(0.4025, grad_fn=<PowBackward1>)\n42\tloss:tensor(9.3301e-06, grad_fn=<MseLossBackward>)\tpow: tensor(0.4031, grad_fn=<PowBackward1>)\n43\tloss:tensor(1.0145e-05, grad_fn=<MseLossBackward>)\tpow: tensor(0.4032, grad_fn=<PowBackward1>)\n44\tloss:tensor(8.2634e-06, grad_fn=<MseLossBackward>)\tpow: tensor(0.4029, grad_fn=<PowBackward1>)\n45\tloss:tensor(4.8482e-06, grad_fn=<MseLossBackward>)\tpow: tensor(0.4022, grad_fn=<PowBackward1>)\n46\tloss:tensor(1.6616e-06, grad_fn=<MseLossBackward>)\tpow: tensor(0.4013, grad_fn=<PowBackward1>)\n47\tloss:tensor(7.9367e-08, grad_fn=<MseLossBackward>)\tpow: tensor(0.4003, grad_fn=<PowBackward1>)\n48\tloss:tensor(4.5216e-07, grad_fn=<MseLossBackward>)\tpow: tensor(0.3993, grad_fn=<PowBackward1>)\n49\tloss:tensor(2.0866e-06, grad_fn=<MseLossBackward>)\tpow: tensor(0.3986, grad_fn=<PowBackward1>)\n50\tloss:tensor(3.7677e-06, grad_fn=<MseLossBackward>)\tpow: tensor(0.3981, grad_fn=<PowBackward1>)\n51\tloss:tensor(4.4713e-06, grad_fn=<MseLossBackward>)\tpow: tensor(0.3979, grad_fn=<PowBackward1>)\n52\tloss:tensor(3.8700e-06, grad_fn=<MseLossBackward>)\tpow: tensor(0.3980, grad_fn=<PowBackward1>)\n53\tloss:tensor(2.3938e-06, grad_fn=<MseLossBackward>)\tpow: tensor(0.3985, grad_fn=<PowBackward1>)\n54\tloss:tensor(8.8012e-07, grad_fn=<MseLossBackward>)\tpow: tensor(0.3991, grad_fn=<PowBackward1>)\n55\tloss:tensor(6.0232e-08, grad_fn=<MseLossBackward>)\tpow: tensor(0.3998, grad_fn=<PowBackward1>)\n56\tloss:tensor(1.7705e-07, grad_fn=<MseLossBackward>)\tpow: tensor(0.4004, grad_fn=<PowBackward1>)\n57\tloss:tensor(9.2600e-07, grad_fn=<MseLossBackward>)\tpow: tensor(0.4010, grad_fn=<PowBackward1>)\n58\tloss:tensor(1.7079e-06, grad_fn=<MseLossBackward>)\tpow: tensor(0.4013, grad_fn=<PowBackward1>)\n59\tloss:tensor(2.0108e-06, grad_fn=<MseLossBackward>)\tpow: tensor(0.4014, grad_fn=<PowBackward1>)\n60\tloss:tensor(1.6853e-06, grad_fn=<MseLossBackward>)\tpow: tensor(0.4013, grad_fn=<PowBackward1>)\n61\tloss:tensor(9.7198e-07, grad_fn=<MseLossBackward>)\tpow: tensor(0.4010, grad_fn=<PowBackward1>)\n62\tloss:tensor(2.9897e-07, grad_fn=<MseLossBackward>)\tpow: tensor(0.4005, grad_fn=<PowBackward1>)\n63\tloss:tensor(3.7911e-09, grad_fn=<MseLossBackward>)\tpow: tensor(0.4001, grad_fn=<PowBackward1>)\n64\tloss:tensor(1.5075e-07, grad_fn=<MseLossBackward>)\tpow: tensor(0.3996, grad_fn=<PowBackward1>)\n65\tloss:tensor(5.3797e-07, grad_fn=<MseLossBackward>)\tpow: tensor(0.3993, grad_fn=<PowBackward1>)\n66\tloss:tensor(8.5983e-07, grad_fn=<MseLossBackward>)\tpow: tensor(0.3991, grad_fn=<PowBackward1>)\n67\tloss:tensor(9.0456e-07, grad_fn=<MseLossBackward>)\tpow: tensor(0.3990, grad_fn=<PowBackward1>)\n68\tloss:tensor(6.6540e-07, grad_fn=<MseLossBackward>)\tpow: tensor(0.3992, grad_fn=<PowBackward1>)\n69\tloss:tensor(3.1062e-07, grad_fn=<MseLossBackward>)\tpow: tensor(0.3994, grad_fn=<PowBackward1>)\n70\tloss:tensor(5.2674e-08, grad_fn=<MseLossBackward>)\tpow: tensor(0.3998, grad_fn=<PowBackward1>)\n71\tloss:tensor(1.1339e-08, grad_fn=<MseLossBackward>)\tpow: tensor(0.4001, grad_fn=<PowBackward1>)\n72\tloss:tensor(1.5447e-07, grad_fn=<MseLossBackward>)\tpow: tensor(0.4004, grad_fn=<PowBackward1>)\n73\tloss:tensor(3.4270e-07, grad_fn=<MseLossBackward>)\tpow: tensor(0.4006, grad_fn=<PowBackward1>)\n74\tloss:tensor(4.3376e-07, grad_fn=<MseLossBackward>)\tpow: tensor(0.4007, grad_fn=<PowBackward1>)\n75\tloss:tensor(3.7246e-07, grad_fn=<MseLossBackward>)\tpow: tensor(0.4006, grad_fn=<PowBackward1>)\n76\tloss:tensor(2.1124e-07, grad_fn=<MseLossBackward>)\tpow: tensor(0.4005, grad_fn=<PowBackward1>)\n77\tloss:tensor(5.8590e-08, grad_fn=<MseLossBackward>)\tpow: tensor(0.4002, grad_fn=<PowBackward1>)\n78\tloss:tensor(4.2286e-12, grad_fn=<MseLossBackward>)\tpow: tensor(0.4000, grad_fn=<PowBackward1>)\n79\tloss:tensor(4.6518e-08, grad_fn=<MseLossBackward>)\tpow: tensor(0.3998, grad_fn=<PowBackward1>)\n80\tloss:tensor(1.4000e-07, grad_fn=<MseLossBackward>)\tpow: tensor(0.3996, grad_fn=<PowBackward1>)\n81\tloss:tensor(2.0257e-07, grad_fn=<MseLossBackward>)\tpow: tensor(0.3995, grad_fn=<PowBackward1>)\n82\tloss:tensor(1.9091e-07, grad_fn=<MseLossBackward>)\tpow: tensor(0.3996, grad_fn=<PowBackward1>)\n83\tloss:tensor(1.1910e-07, grad_fn=<MseLossBackward>)\tpow: tensor(0.3997, grad_fn=<PowBackward1>)\n84\tloss:tensor(3.9360e-08, grad_fn=<MseLossBackward>)\tpow: tensor(0.3998, grad_fn=<PowBackward1>)\n85\tloss:tensor(8.2367e-10, grad_fn=<MseLossBackward>)\tpow: tensor(0.4000, grad_fn=<PowBackward1>)\n86\tloss:tensor(1.6985e-08, grad_fn=<MseLossBackward>)\tpow: tensor(0.4001, grad_fn=<PowBackward1>)\n87\tloss:tensor(6.2446e-08, grad_fn=<MseLossBackward>)\tpow: tensor(0.4002, grad_fn=<PowBackward1>)\n88\tloss:tensor(9.6676e-08, grad_fn=<MseLossBackward>)\tpow: tensor(0.4003, grad_fn=<PowBackward1>)\n89\tloss:tensor(9.4282e-08, grad_fn=<MseLossBackward>)\tpow: tensor(0.4003, grad_fn=<PowBackward1>)\n90\tloss:tensor(5.9940e-08, grad_fn=<MseLossBackward>)\tpow: tensor(0.4002, grad_fn=<PowBackward1>)\n91\tloss:tensor(2.0031e-08, grad_fn=<MseLossBackward>)\tpow: tensor(0.4001, grad_fn=<PowBackward1>)\n92\tloss:tensor(4.2655e-10, grad_fn=<MseLossBackward>)\tpow: tensor(0.4000, grad_fn=<PowBackward1>)\n93\tloss:tensor(8.6071e-09, grad_fn=<MseLossBackward>)\tpow: tensor(0.3999, grad_fn=<PowBackward1>)\n94\tloss:tensor(3.1433e-08, grad_fn=<MseLossBackward>)\tpow: tensor(0.3998, grad_fn=<PowBackward1>)\n95\tloss:tensor(4.7929e-08, grad_fn=<MseLossBackward>)\tpow: tensor(0.3998, grad_fn=<PowBackward1>)\n96\tloss:tensor(4.5533e-08, grad_fn=<MseLossBackward>)\tpow: tensor(0.3998, grad_fn=<PowBackward1>)\n97\tloss:tensor(2.7546e-08, grad_fn=<MseLossBackward>)\tpow: tensor(0.3998, grad_fn=<PowBackward1>)\n98\tloss:tensor(8.0898e-09, grad_fn=<MseLossBackward>)\tpow: tensor(0.3999, grad_fn=<PowBackward1>)\n99\tloss:tensor(9.4227e-12, grad_fn=<MseLossBackward>)\tpow: tensor(0.4000, grad_fn=<PowBackward1>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "y = torch.tensor(0.6, requires_grad=True)\n",
    "true = torch.tensor([0.4])\n",
    "loss_func = nn.MSELoss()\n",
    "optimizer = Adam([x,y],lr=0.01)\n",
    "for i in range(100):\n",
    "    pow = torch.pow(y,x)\n",
    "    pow_tensor = pow.unsqueeze(0)\n",
    "    loss = loss_func(pow_tensor, true)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(str(i)+'\\tloss:'+ str(loss)+'\\tpow: '+ str(pow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Module\n",
    "class Pow_Model(Module):\n",
    "    def __init__()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}